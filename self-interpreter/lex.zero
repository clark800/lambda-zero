--* lex.zero

LocationType ::= {Location(
    getLocationFile : List(Integer),
    getLocationLine : Integer,
    getLocationColumn : Integer
)}

TagType ::= {Tag(getTagLexeme : List(Integer), getTagLocation : LocationType)}

isDelimiter(n) := " \n\0,;.`()[]{}@$\"".any((= n))
isLineComment(lexeme) := lexeme.startsWith("--")
isBlockComment(lexeme) := lexeme.startsWith("{=")
isNumeric(lexeme) := isDigit(head(lexeme)) \/
    ((head(lexeme) = '+' \/ head(lexeme) = '-') /\ ! isNil(tail(lexeme)) /\
      isDigit(head(tail(lexeme))))
isInvalid(c) := c < 0 \/ (isControl(c) /\ ! isWhitespace(c) /\ c != 0)
isSpace(c) := c > 0 /\ isWhitespace(c) /\ c != '\n'

splitQuoteCharacter(quote, ns) := (
    ns.isNil \/ head(ns) = quote \/ head(ns) = '\n' ? ([], ns)
    n := (head(ns) = '\\' /\ ! isNil(tail(ns))) ? 2 || 1
    ns.splitAt(n)
)

shiftSplit((a, b)) := isNil(b) ? (a, b) || (a ++ [head(b)], tail(b))

splitQuote(ns) := (
    quote := head(ns)
    (a, b) := tail(ns).splitWith(splitQuoteCharacter(quote))
    ! b.isNil /\ head(b) = quote ?
        shiftSplit((quote :: a, b))
    (quote :: a, b)
)

splitNumeric(ns) := (
    (before, after) := ns.splitWhen(isDelimiter)
    isNil(after) \/ isNil(tail(after)) \/ head(after) != '.' \/
        ! isDigit(head(tail(after))) ? (before, after)
    (before', after') := tail(after).splitWhen(isDelimiter)
    (before ++ [head(after)] ++ before', after')
)

splitLexeme(ns) := (
    ns.isNil ? ([], [])
    c := head(ns)
    c.isBlank ? ns.splitWhen((!) <> isBlank)
    c.isQuote ? splitQuote(ns)
    ns.isLineComment ? ns.splitOn("\n")
    ns.isBlockComment ? ns.splitOn("=}").shiftSplit.shiftSplit
    ns.isNumeric ? splitNumeric(ns)
    c = '.' ? ns.splitWhen(!= '.')
    c.isDelimiter ? ([head(ns)], tail(ns))
    ns.splitWhen(isDelimiter)
)

advanceLocation'(lexeme, line, column) := (
    isNil(lexeme) ? (line, column)
    head(lexeme) = '\n' ? tail(lexeme).advanceLocation'(line + 1, 1)
    tail(lexeme).advanceLocation'(line, column + 1)
)

advanceLocation(location, lexeme) := (
    isLineComment(lexeme) /\ lexeme[2] = '*' ? (
        (_, after) := lexeme.drop(3).splitWhen((!) <> isSpace)
        (file, _) := after.splitWhen(= '\n')
        Location(file, isNil(file) ? 0 || 1, 0)
    )
    isBlockComment(lexeme) ? (
        (line, column) := lexeme.advanceLocation'(
            location.getLocationLine, location.getLocationColumn)
        Location(location.getLocationFile, line, column)
    )
    head(lexeme) = '\n' ?
        Location(location.getLocationFile, location.getLocationLine + 1, 1)
    Location(location.getLocationFile, location.getLocationLine,
        location.getLocationColumn + length(lexeme))
)

splitLexemes(string, splitter, location) := (
    string.isNil ? []
    (lexeme, remaining) := splitter(string)
    nextLocation := advanceLocation(location, lexeme)
    Tag(lexeme, location) :: remaining.splitLexemes(splitter, nextLocation)
)

scan(string) := string.splitLexemes(splitLexeme, Location("", 1, 1))

showLocation(location) :=
    (location.getLocationFile.isNil ? "" || location.getLocationFile ++ " ") ++
    "line " ++ showNatural(location.getLocationLine) ++
    " column " ++ showNatural(location.getLocationColumn)

showTag(tag) :=
    "'" ++ tag.getTagLexeme ++
    "' at " ++ showLocation(tag.getTagLocation)

TokenCode ::= {Space, Symbolic, Numeric, Character, String, Comment, Invalid}
TokenType ::= {Token(getTokenTag : Tag, getTokenCode : TokenCode)}

createToken(tag) := (
    lexeme := getTagLexeme(tag)
    isNil(lexeme) ? Token(tag, Symbolic)
    c := head(lexeme)
    isInvalid(c) ? Token(tag, Invalid)
    isSpace(c) ? Token(tag, Space)
    c = '"' ? Token(tag, String)
    c = '\'' ? Token(tag, Character)
    isNumeric(lexeme) ? Token(tag, Numeric)
    isLineComment(lexeme) \/ isBlockComment(lexeme) ? Token(tag, Comment)
    Token(tag, Symbolic)
)

getTokenCodeNumber(tokenCode) := tokenCode.match(
    Space -> 0;
    Symbolic -> 1;
    Numeric -> 2;
    Character -> 3;
    String -> 4;
    Comment -> 5;
    Invalid -> 6;
)

isComment(token) := getTokenCodeNumber(getTokenCode(token)) =
                   getTokenCodeNumber(Comment)

showToken(token) := token.getTokenTag.getTagLexeme

lex(string) := scan(string).map(createToken)

START := Token(Tag("\0", Location("", 0, 0)), Symbolic)

showToken'(token) := showTag(getTokenTag(token)) ++ " " ++
    getTokenCode(token).match(
        Space -> "Space";
        Symbolic -> "Symbolic";
        Numeric -> "Numeric";
        Character -> "Character";
        String -> "String";
        Comment -> "Comment";
        Invalid -> "Invalid";
    )

--main(input) := scan(input).map(showTag).joinWith("\n")
--main(input) := lex(input).map(showToken').joinWith("\n")

--*
