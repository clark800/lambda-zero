#* lex.zero

Location ::= {Location(_file : List(ℕ), _line : ℕ, _column : ℕ)}
Tag ::= {Tag(getTagLexeme : List(ℕ), getTagLocation : Location)}

renameTag(Tag(_, location), lexeme) := Tag(lexeme, location)

isComment(c) := c = '#'
isLineFeed(c) := c = '\n'
isInvalid(c) := c =/= 0 and isControl(c) and not isLineFeed(c)
isDelimiter(c) := " `.,;@#$()[]{}\"\n\0".any((= c)) or isInvalid(c)
isRepeatable(c) := " `.,;".any(= c)

define startsWithDigit(lexeme)
    lexeme |> [] -> False; n :: _ -> isDigit(n)

define isNumeric(lexeme)
    lexeme |> [] -> False; n :: ns ->
        isDigit(n) or ((n = '+' or n = '-') and startsWithDigit(ns))

define splitQuoteCharacter(quote, ns)
    match ns
        case []; ([], ns)
        case n :: ns'
            if n = quote or isLineFeed(n)
                ([], ns)
            n' := if n = '\\' and not isNil(ns') then 2 else 1
            ns.splitAt(n')

define shiftSplit((a, b))
    b |> [] -> (a, b); n :: ns -> (a ++ [n], ns)

define splitQuote(ns)
    match ns
        case []; ([], [])
        case quote :: ns'
            (a, b) := ns'.splitWith(splitQuoteCharacter(quote))
            match b
                case []
                    (quote :: a, b)
                case quote' :: _
                    if quote' = quote
                        shiftSplit((quote :: a, b))
                    (quote :: a, b)

define splitNumeric(ns)
    (before, after) := ns.splitWhen(isDelimiter)
    match after
        case []
            (before, after)
        case n :: ns'
            if n =/= '.' or not startsWithDigit(ns')
                (before, after)
            (before', after') := ns'.splitWhen(isDelimiter)
            (before ++ [n] ++ before', after')

define splitNewline(ns)
    match ns
        case []; ([], [])
        case n :: ns'
            (before, after) := ns'.splitWhen(=/= ' ')
            (n :: before, after)

define splitLexeme(ns)
    match ns
        case []; ([], [])
        case c :: ns'
            if c.isLineFeed then splitNewline(ns)
            if c.isQuote then splitQuote(ns)
            if c.isComment then ns.splitWhen(isLineFeed)
            if ns.isNumeric then splitNumeric(ns)
            if c.isRepeatable then ns.splitWhen(=/= c)
            if c.isDelimiter then ([c], ns')
            ns.splitWhen(isDelimiter)

define advanceLocation(Location(file, line, column), lexeme)
    if lexeme.startsWith("#*")
        (_, after) := lexeme.drop(2).splitWhen(=/= ' ')
        (file', _) := after.splitWhen(isLineFeed)
        Location(file', if isNil(file') then 0 else 1, 0)
    if lexeme.startsWith("\n")
        Location(file, line + 1, length(lexeme))
    Location(file, line, column + length(lexeme))

define splitLexemes(splitter, location, string)
    if string.isNil
        []
    (lexeme, remaining) := splitter(string)
    nextLocation := advanceLocation(location, lexeme)
    Tag(lexeme, location) :: remaining.splitLexemes(splitter, nextLocation)

define scan(string)
    string.splitLexemes(splitLexeme, Location("", 1, 1))

define showLocation(Location(file, line, column))
    (if isNil(file) then "" else file ++ " ") ++
        "line " ++ showNatural(line) ++ " column " ++ showNatural(column)

define showFullTag(Tag(lexeme, location))
    "'" ++ lexeme ++ "' at " ++ showLocation(location)

define showTag(Tag(lexeme, _))
    match lexeme
        case []; "\\0"
        case c :: _
            if c = 0 then "\\0"
            if c = '\n' then "\\n"
            lexeme


TokenCode ::= {
    Space, VSpace, Newline, Symbolic, Numeric, Character, String,
    Comment, Invalid
}
Token ::= {Token(getTokenTag : Tag, getTokenCode : TokenCode)}

define createLineFeedToken(tag, _ @ Tag(nextLexeme, _))
    match nextLexeme
        case []
            Token(tag, VSpace)
        case c :: _
            if isLineFeed(c) or isComment(c)
                Token(tag, VSpace)
            Token(tag, Newline)

define createToken(tag @ Tag(lexeme, _), nextTag)
    match lexeme
        case []
            Token(tag, Symbolic)
        case c :: _
            if c = ' ' then Token(tag, Space)
            if c = '\n' then createLineFeedToken(tag, nextTag)
            if c = '"' then Token(tag, String)
            if c = '\'' then Token(tag, Character)
            if isNumeric(lexeme) then Token(tag, Numeric)
            if isComment(c) then Token(tag, Comment)
            if isInvalid(c) then Token(tag, Invalid)
            Token(tag, Symbolic)

define getTokenCodeNumber(tokenCode)
    match tokenCode
        Space -> 0
        VSpace -> 1
        Newline -> 2
        Symbolic -> 3
        Numeric -> 4
        Character -> 5
        String -> 6
        Comment -> 7
        Invalid -> 8

define isElided(token)
    code := getTokenCodeNumber(getTokenCode(token))
    code = getTokenCodeNumber(Comment) or code = getTokenCodeNumber(VSpace)

define showToken(token)
    showTag(getTokenTag(token))

define noTag
    Tag("", Location("", 0, 0))

define START
    Token(Tag("\0", Location("", 0, 0)), Symbolic)

define lex(string)
    pairs(scan(string) ++ [noTag]).map(uncurry(createToken))

define showFullToken(token)
    showFullTag(getTokenTag(token)) ++ " " ++ (
        match getTokenCode(token)
            Space -> "Space"
            VSpace -> "VSpace"
            Newline -> "Newline"
            Symbolic -> "Symbolic"
            Numeric -> "Numeric"
            Character -> "Character"
            String -> "String"
            Comment -> "Comment"
            Invalid -> "Invalid"
    )

#main(input) := scan(input).map(showTag).joinWith("\n")
#main(input) := lex(input).map(showFullToken).joinWith("\n")

#*
