--* lex.zero

LocationType ::= {Location(
    getLocationFile : List(Integer),
    getLocationLine : Integer,
    getLocationColumn : Integer
)}

TagType ::= {Tag(getTagLexeme : List(Integer), getTagLocation : LocationType)}

isLineComment(lexeme) := lexeme.startsWith("--")
isBlockComment(lexeme) := lexeme.startsWith("{=")
isNumeric(lexeme) := isDigit(head(lexeme)) \/
    ((head(lexeme) = '+' \/ head(lexeme) = '-') /\ not isNil(tail(lexeme)) /\
      isDigit(head(tail(lexeme))))
isLineFeed(c) := c = '\n'
isInvalid(c) := c =/= 0 /\ isControl(c) /\ not isLineFeed(c)
isDelimiter(c) := " `.,;@$()[]{}\"\n\0".any((= c)) \/ isInvalid(c)
isRepeatable(c) := " `.,;".any(= c)

splitQuoteCharacter(quote, ns) := (
    ns.isNil \/ head(ns) = quote \/ isLineFeed(head(ns)) ? ([], ns)
    n := (head(ns) = '\\' /\ not isNil(tail(ns))) ? 2 || 1
    ns.splitAt(n)
)

shiftSplit((a, b)) := isNil(b) ? (a, b) || (a ++ [head(b)], tail(b))

splitQuote(ns) := (
    quote := head(ns)
    (a, b) := tail(ns).splitWith(splitQuoteCharacter(quote))
    not b.isNil /\ head(b) = quote ?
        shiftSplit((quote :: a, b))
    (quote :: a, b)
)

splitNumeric(ns) := (
    (before, after) := ns.splitWhen(isDelimiter)
    isNil(after) \/ isNil(tail(after)) \/ head(after) =/= '.' \/
        not isDigit(head(tail(after))) ? (before, after)
    (before', after') := tail(after).splitWhen(isDelimiter)
    (before ++ [head(after)] ++ before', after')
)

splitNewline(ns) := (
    (before, after) := tail(ns).splitWhen(=/= ' ')
    (head(ns) :: before, after)
)

splitLexeme(ns) := (
    ns.isNil ? ([], [])
    c := head(ns)
    c.isLineFeed ? splitNewline(ns)
    c.isQuote ? splitQuote(ns)
    ns.isLineComment ? ns.splitWhen(isLineFeed)
    ns.isBlockComment ? ns.splitOn("=}").shiftSplit.shiftSplit
    ns.isNumeric ? splitNumeric(ns)
    c.isRepeatable ? ns.splitWhen(=/= c)
    c.isDelimiter ? ([head(ns)], tail(ns))
    ns.splitWhen(isDelimiter)
)

advanceLocation'(lexeme, line, column) := (
    isNil(lexeme) ? (line, column)
    isLineFeed(head(lexeme)) ? tail(lexeme).advanceLocation'(line + 1, 1)
    tail(lexeme).advanceLocation'(line, column + 1)
)

advanceLocation(location, lexeme) := (
    isLineComment(lexeme) /\ lexeme[2] = '*' ? (
        (_, after) := lexeme.drop(3).splitWhen(=/= ' ')
        (file, _) := after.splitWhen(isLineFeed)
        Location(file, isNil(file) ? 0 || 1, 0)
    )
    isBlockComment(lexeme) \/ isLineFeed(head(lexeme)) ? (
        (line, column) := lexeme.advanceLocation'(
            location.getLocationLine, location.getLocationColumn)
        Location(location.getLocationFile, line, column)
    )
    Location(location.getLocationFile, location.getLocationLine,
        location.getLocationColumn + length(lexeme))
)

splitLexemes(string, splitter, location) := (
    string.isNil ? []
    (lexeme, remaining) := splitter(string)
    nextLocation := advanceLocation(location, lexeme)
    Tag(lexeme, location) :: remaining.splitLexemes(splitter, nextLocation)
)

scan(string) := string.splitLexemes(splitLexeme, Location("", 1, 1))

showLocation(location) :=
    (location.getLocationFile.isNil ? "" || location.getLocationFile ++ " ") ++
    "line " ++ showNatural(location.getLocationLine) ++
    " column " ++ showNatural(location.getLocationColumn)

showTag(tag) :=
    "'" ++ tag.getTagLexeme ++
    "' at " ++ showLocation(tag.getTagLocation)

TokenCode ::= {
    Space, VSpace, Newline, Symbolic, Numeric, Character, String,
    Comment, Invalid
}
TokenType ::= {Token(getTokenTag : Tag, getTokenCode : TokenCode)}

createLineFeedToken(tag, nextTag) := (
    nextLexeme := getTagLexeme(nextTag)
    not isNil(nextLexeme) /\ head(nextLexeme) = '\n' ?
        Token(tag, VSpace)
    Token(tag, Newline)
)

createToken(tag, nextTag) := (
    lexeme := getTagLexeme(tag)
    isNil(lexeme) ? Token(tag, Symbolic)
    c := head(lexeme)
    c = ' ' ? Token(tag, Space)
    c = '\n' ? createLineFeedToken(tag, nextTag)
    c = '"' ? Token(tag, String)
    c = '\'' ? Token(tag, Character)
    isNumeric(lexeme) ? Token(tag, Numeric)
    isLineComment(lexeme) \/ isBlockComment(lexeme) ? Token(tag, Comment)
    isInvalid(c) ? Token(tag, Invalid)
    Token(tag, Symbolic)
)

getTokenCodeNumber(tokenCode) := tokenCode.match(
    Space -> 0;
    VSpace -> 1;
    Newline -> 2;
    Symbolic -> 3;
    Numeric -> 4;
    Character -> 5;
    String -> 6;
    Comment -> 7;
    Invalid -> 8;
)

isElided(token) := (
    code := getTokenCodeNumber(getTokenCode(token))
    code = getTokenCodeNumber(Comment) \/ code = getTokenCodeNumber(VSpace)
)

showToken(token) := token.getTokenTag.getTagLexeme

EOF_TAG := Tag("\0", Location("", 0, 0))

START := Token(EOF_TAG, Symbolic)

lex(string) := pairs(scan(string) ++ [EOF_TAG]).map(uncurry(createToken))

showToken'(token) := showTag(getTokenTag(token)) ++ " " ++
    getTokenCode(token).match(
        Space -> "Space";
        VSpace -> "VSpace";
        Newline -> "Newline";
        Symbolic -> "Symbolic";
        Numeric -> "Numeric";
        Character -> "Character";
        String -> "String";
        Comment -> "Comment";
        Invalid -> "Invalid";
    )

--main(input) := scan(input).map(showTag).joinWith("\n")
--main(input) := lex(input).map(showToken').joinWith("\n")

--*
