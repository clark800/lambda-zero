#* lex.zero

LocationType ::= {Location(_file : List(ℕ), _line : ℕ, _column : ℕ)}
TagType ::= {Tag(getTagLexeme : List(ℕ), getTagLocation : LocationType)}

renameTag(Tag(_, location), lexeme) := Tag(lexeme, location)

isComment(c) := c = '#'
isLineFeed(c) := c = '\n'
isInvalid(c) := c =/= 0 and isControl(c) and not isLineFeed(c)
isDelimiter(c) := " `.,;@#$()[]{}\"\n\0".any((= c)) or isInvalid(c)
isRepeatable(c) := " `.,;".any(= c)

define isNumeric(lexeme)
    isDigit(head(lexeme)) or ((head(lexeme) = '+' or head(lexeme) = '-') and
        not isNil(tail(lexeme)) and isDigit(head(tail(lexeme))))

define splitQuoteCharacter(quote, ns)
    if ns.isNil or head(ns) = quote or isLineFeed(head(ns))
        ([], ns)
    n := if head(ns) = '\\' and not isNil(tail(ns)) then 2 else 1
    ns.splitAt(n)

define shiftSplit((a, b))
    if isNil(b)
        (a, b)
    (a ++ [head(b)], tail(b))

define splitQuote(ns)
    quote := head(ns)
    (a, b) := tail(ns).splitWith(splitQuoteCharacter(quote))
    if not b.isNil and head(b) = quote
        shiftSplit((quote :: a, b))
    (quote :: a, b)

define splitNumeric(ns)
    (before, after) := ns.splitWhen(isDelimiter)
    if isNil(after) or isNil(tail(after)) or head(after) =/= '.' or
            not isDigit(head(tail(after)))
        (before, after)
    (before', after') := tail(after).splitWhen(isDelimiter)
    (before ++ [head(after)] ++ before', after')

define splitNewline(ns)
    (before, after) := tail(ns).splitWhen(=/= ' ')
    (head(ns) :: before, after)

define splitLexeme(ns)
    if ns.isNil then ([], [])
    c := head(ns)
    if c.isLineFeed then splitNewline(ns)
    if c.isQuote then splitQuote(ns)
    if c.isComment then ns.splitWhen(isLineFeed)
    if ns.isNumeric then splitNumeric(ns)
    if c.isRepeatable then ns.splitWhen(=/= c)
    if c.isDelimiter then ([head(ns)], tail(ns))
    ns.splitWhen(isDelimiter)

define advanceLocation(Location(file, line, column), lexeme)
    if isComment(lexeme[0]) and lexeme[1] = '*'
        (_, after) := lexeme.drop(2).splitWhen(=/= ' ')
        (file', _) := after.splitWhen(isLineFeed)
        Location(file', if isNil(file') then 0 else 1, 0)
    if isLineFeed(head(lexeme))
        Location(file, line + 1, length(lexeme))
    Location(file, line, column + length(lexeme))

define splitLexemes(splitter, location, string)
    if string.isNil
        []
    (lexeme, remaining) := splitter(string)
    nextLocation := advanceLocation(location, lexeme)
    Tag(lexeme, location) :: remaining.splitLexemes(splitter, nextLocation)

define scan(string)
    string.splitLexemes(splitLexeme, Location("", 1, 1))

define showLocation(Location(file, line, column))
    (if isNil(file) then "" else file ++ " ") ++
        "line " ++ showNatural(line) ++ " column " ++ showNatural(column)

define showFullTag(Tag(lexeme, location))
    "'" ++ lexeme ++ "' at " ++ showLocation(location)

define showTag(Tag(lexeme, _))
    if lexeme.isNil or head(lexeme) = 0 then "\\0"
    if head(lexeme) = '\n' then "\\n"
    lexeme


TokenCode ::= {
    Space, VSpace, Newline, Symbolic, Numeric, Character, String,
    Comment, Invalid
}
TokenType ::= {Token(getTokenTag : TagType, getTokenCode : TokenCode)}

define createLineFeedToken(tag, _ @ Tag(nextLexeme, _))
    if isNil(nextLexeme) or
            head(nextLexeme).isLineFeed or isComment(head(nextLexeme))
        Token(tag, VSpace)
    Token(tag, Newline)

define createToken(tag @ Tag(lexeme, _), nextTag)
    if isNil(lexeme) then Token(tag, Symbolic)
    c := head(lexeme)
    if c = ' ' then Token(tag, Space)
    if c = '\n' then createLineFeedToken(tag, nextTag)
    if c = '"' then Token(tag, String)
    if c = '\'' then Token(tag, Character)
    if isNumeric(lexeme) then Token(tag, Numeric)
    if isComment(c) then Token(tag, Comment)
    if isInvalid(c) then Token(tag, Invalid)
    Token(tag, Symbolic)

define getTokenCodeNumber(tokenCode)
    match tokenCode
        Space -> 0
        VSpace -> 1
        Newline -> 2
        Symbolic -> 3
        Numeric -> 4
        Character -> 5
        String -> 6
        Comment -> 7
        Invalid -> 8

define isElided(token)
    code := getTokenCodeNumber(getTokenCode(token))
    code = getTokenCodeNumber(Comment) or code = getTokenCodeNumber(VSpace)

define showToken(token)
    showTag(getTokenTag(token))

define noTag
    Tag("", Location("", 0, 0))

define START
    Token(Tag("\0", Location("", 0, 0)), Symbolic)

define lex(string)
    pairs(scan(string) ++ [noTag]).map(uncurry(createToken))

define showFullToken(token)
    showFullTag(getTokenTag(token)) ++ " " ++ (
        match getTokenCode(token)
            Space -> "Space"
            VSpace -> "VSpace"
            Newline -> "Newline"
            Symbolic -> "Symbolic"
            Numeric -> "Numeric"
            Character -> "Character"
            String -> "String"
            Comment -> "Comment"
            Invalid -> "Invalid"
    )

#main(input) := scan(input).map(showTag).joinWith("\n")
#main(input) := lex(input).map(showFullToken).joinWith("\n")

#*
