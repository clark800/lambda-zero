#* lex.zero

NOFIX := 0
PREFIX := 1
INFIX := 2
POSTFIX := 3
OPENFIX := 4
CLOSEFIX := 5

LocationT ::= {Location(_file : List(ℕ), _line : ℕ, _column : ℕ)}
TagT ::= {
    Tag(getTagLexeme : List(ℕ), getTagFixity : ℕ, getTagLocation : LocationT)
}

renameTag(Tag(_, _, location), lexeme, fixity) := Tag(lexeme, fixity, location)
veil(tag) := renameTag(tag, "_", NOFIX)
setTagLocation(location, Tag(lexeme, fixity, _)) :=
    Tag(lexeme, fixity, location)
addPrefix(Tag(lexeme, fixity, location), prefix) :=
    Tag(prefix :: lexeme, fixity, location)
isSameLocation(Location(file1, line1, col1), Location(file2, line2, col2)) :=
    file1 =*= file2 and line1 = line2 and col1 = col2
isSameTag(tag1, tag2) :=
    isSameLocation(getTagLocation(tag1), getTagLocation(tag2))

isComment(c) := c = '#'
isLineFeed(c) := c = '\n'
isInvalid(c) := c =/= 0 and isControl(c) and not isLineFeed(c)
isDelimiter(c) := " `.,;@#$()[]{}\"\n\0".any((= c)) or isInvalid(c)
isRepeatable(c) := " `.,;".any(= c)

define startsWithDigit(lexeme)
    with lexeme as n :: _
        isDigit(n)
    False

define isNumeric(lexeme)
    with lexeme as n :: ns
        isDigit(n) or ((n = '+' or n = '-') and startsWithDigit(ns))
    False

define splitQuoteCharacter(quote, ns)
    with ns as n :: ns'
        if n = quote or isLineFeed(n)
            ([], ns)
        n' := if n = '\\' and not isNil(ns') then 2 else 1
        ns.splitAt(n')
    ([], ns)

define shiftSplit((a, b))
    b |> [] -> (a, b); n :: ns -> (a ++ [n], ns)

define splitQuote(ns)
    with ns as quote :: ns'
        (a, b) := ns'.splitWith(splitQuoteCharacter(quote))
        with b as quote' :: _
            if quote' = quote
                shiftSplit((quote :: a, b))
            (quote :: a, b)
        (quote :: a, b)
    ([], [])

define splitNumeric(ns)
    (before, after) := ns.splitWhen(isDelimiter)
    with after as n :: ns'
        if n =/= '.' or not startsWithDigit(ns')
            (before, after)
        (before', after') := ns'.splitWhen(isDelimiter)
        (before ++ [n] ++ before', after')
    (before, after)

define splitNewline(ns)
    with ns as n :: ns'
        (before, after) := ns'.splitWhen(=/= ' ')
        (n :: before, after)
    ([], [])

define splitLexeme(ns)
    with ns as c :: ns'
        if c.isLineFeed then splitNewline(ns)
        if c.isQuote then splitQuote(ns)
        if c.isComment then ns.splitWhen(isLineFeed)
        if ns.isNumeric then splitNumeric(ns)
        if c.isRepeatable then ns.splitWhen(=/= c)
        if c.isDelimiter then ([c], ns')
        ns.splitWhen(isDelimiter)
    ([], [])

define advanceLocation(Location(file, line, column), lexeme)
    if lexeme.startsWith("#*")
        (_, after) := lexeme.drop(2).splitWhen(=/= ' ')
        (file', _) := after.splitWhen(isLineFeed)
        Location(file', if isNil(file') then 0 else 1, 0)
    if lexeme.startsWith("\n")
        Location(file, line + 1, length(lexeme))
    Location(file, line, column + length(lexeme))

define splitLexemes(splitter, location, string)
    if string.isNil
        []
    (lexeme, remaining) := splitter(string)
    nextLocation := advanceLocation(location, lexeme)
    Tag(lexeme, NOFIX, location) ::
        remaining.splitLexemes(splitter, nextLocation)

define scan(string)
    string.splitLexemes(splitLexeme, Location("", 1, 1))

define showLocation(Location(file, line, column))
    (if isNil(file) then "" else file ++ " ") ++
        "line " ++ showNatural(line) ++ " column " ++ showNatural(column)

define showFullTag(Tag(lexeme, _, location))
    "'" ++ lexeme ++ "' at " ++ showLocation(location)

define showTag(Tag(lexeme, fixity, _))
    with lexeme as c :: _
        if c = 0 then "\\0"
        if c = '\n' then "\\n"
        if fixity = NOFIX then lexeme
        "(" ++ lexeme ++ ")"
    "\\0"


TokenCode ::= {
    Space, VSpace, Newline, Symbolic, Numeric, Character, String,
    Comment, Invalid
}
Token ::= {Token(getTokenTag : TagT, getTokenCode : TokenCode)}

define createLineFeedToken(tag, _ @ Tag(nextLexeme, _, _))
    with nextLexeme as c :: _
        if isLineFeed(c) or isComment(c)
            Token(tag, VSpace)
        Token(tag, Newline)
    Token(tag, VSpace)

define createToken(tag @ Tag(lexeme, _, _), nextTag)
    with lexeme as c :: _
        if c = ' ' then Token(tag, Space)
        if c = '\n' then createLineFeedToken(tag, nextTag)
        if c = '"' then Token(tag, String)
        if c = '\'' then Token(tag, Character)
        if isNumeric(lexeme) then Token(tag, Numeric)
        if isComment(c) then Token(tag, Comment)
        if isInvalid(c) then Token(tag, Invalid)
        Token(tag, Symbolic)
    Token(tag, Symbolic)

define isElided(token)
    code := getTokenCode(token)
    with code as Comment
        True
    with code as VSpace
        True
    False

define showToken(token)
    showTag(getTokenTag(token))

define noTag
    Tag("", NOFIX, Location("", 0, 0))

define START
    Token(Tag("\0", NOFIX, Location("", 0, 0)), Symbolic)

define lex(string)
    pairs(scan(string) ++ [noTag]).map(uncurry(createToken))

define showFullToken(token)
    showFullTag(getTokenTag(token)) ++ " " ++ (
        match getTokenCode(token)
            Space -> "Space"
            VSpace -> "VSpace"
            Newline -> "Newline"
            Symbolic -> "Symbolic"
            Numeric -> "Numeric"
            Character -> "Character"
            String -> "String"
            Comment -> "Comment"
            Invalid -> "Invalid"
    )

#main(input) := scan(input).map(showTag).joinWith("\n")
#main(input) := lex(input).map(showFullToken).joinWith("\n")

#*
