#* lex.zero

LocationType ::= {Location(
    getLocationFile : List(Integer),
    getLocationLine : Integer,
    getLocationColumn : Integer
)}

TagType ::= {Tag(getTagLexeme : List(Integer), getTagLocation : LocationType)}

isComment(c) := c = '#'
isLineFeed(c) := c = '\n'
isInvalid(c) := c =/= 0 and isControl(c) and not isLineFeed(c)
isDelimiter(c) := " `.,;@#$()[]{}\"\n\0".any((= c)) or isInvalid(c)
isRepeatable(c) := " `.,;".any(= c)

define isNumeric(lexeme)
    isDigit(head(lexeme)) or ((head(lexeme) = '+' or head(lexeme) = '-') and
        not isNil(tail(lexeme)) and isDigit(head(tail(lexeme))))

define splitQuoteCharacter(quote, ns)
    if ns.isNil or head(ns) = quote or isLineFeed(head(ns))
        ([], ns)
    n := (head(ns) = '\\' and not isNil(tail(ns))) ? 2 || 1
    ns.splitAt(n)

define shiftSplit((a, b))
    if isNil(b)
        (a, b)
    (a ++ [head(b)], tail(b))

define splitQuote(ns)
    quote := head(ns)
    (a, b) := tail(ns).splitWith(splitQuoteCharacter(quote))
    if not b.isNil and head(b) = quote
        shiftSplit((quote :: a, b))
    (quote :: a, b)

define splitNumeric(ns)
    (before, after) := ns.splitWhen(isDelimiter)
    if isNil(after) or isNil(tail(after)) or head(after) =/= '.' or
            not isDigit(head(tail(after)))
        (before, after)
    (before', after') := tail(after).splitWhen(isDelimiter)
    (before ++ [head(after)] ++ before', after')

define splitNewline(ns)
    (before, after) := tail(ns).splitWhen(=/= ' ')
    (head(ns) :: before, after)

define splitLexeme(ns)
    ns.isNil ? ([], [])
    c := head(ns)
    c.isLineFeed ? splitNewline(ns)
    c.isQuote ? splitQuote(ns)
    c.isComment ? ns.splitWhen(isLineFeed)
    ns.isNumeric ? splitNumeric(ns)
    c.isRepeatable ? ns.splitWhen(=/= c)
    c.isDelimiter ? ([head(ns)], tail(ns))
    ns.splitWhen(isDelimiter)

define advanceLocation(location, lexeme)
    if isComment(lexeme[0]) and lexeme[1] = '*'
        (_, after) := lexeme.drop(2).splitWhen(=/= ' ')
        (file, _) := after.splitWhen(isLineFeed)
        Location(file, isNil(file) ? 0 || 1, 0)
    file := getLocationFile(location)
    line := getLocationLine(location)
    column := getLocationColumn(location)
    if isLineFeed(head(lexeme))
        Location(file, line + 1, length(lexeme))
    Location(file, line, column + length(lexeme))

define splitLexemes(string, splitter, location)
    if string.isNil
        []
    (lexeme, remaining) := splitter(string)
    nextLocation := advanceLocation(location, lexeme)
    Tag(lexeme, location) :: remaining.splitLexemes(splitter, nextLocation)

define scan(string)
    string.splitLexemes(splitLexeme, Location("", 1, 1))

define showLocation(location)
    (location.getLocationFile.isNil ? "" || location.getLocationFile ++ " ") ++
    "line " ++ showNatural(location.getLocationLine) ++
    " column " ++ showNatural(location.getLocationColumn)

define showTag(tag)
    "'" ++ tag.getTagLexeme ++ "' at " ++ showLocation(tag.getTagLocation)

TokenCode ::= {
    Space, VSpace, Newline, Symbolic, Numeric, Character, String,
    Comment, Invalid
}
TokenType ::= {Token(getTokenTag : Tag, getTokenCode : TokenCode)}

define createLineFeedToken(tag, nextTag)
    nextLexeme := getTagLexeme(nextTag)
    if isNil(nextLexeme) or
            head(nextLexeme).isLineFeed or isComment(head(nextLexeme))
        Token(tag, VSpace)
    Token(tag, Newline)

define createToken(tag, nextTag)
    lexeme := getTagLexeme(tag)
    isNil(lexeme) ? Token(tag, Symbolic)
    c := head(lexeme)
    c = ' ' ? Token(tag, Space)
    c = '\n' ? createLineFeedToken(tag, nextTag)
    c = '"' ? Token(tag, String)
    c = '\'' ? Token(tag, Character)
    isNumeric(lexeme) ? Token(tag, Numeric)
    isComment(c) ? Token(tag, Comment)
    isInvalid(c) ? Token(tag, Invalid)
    Token(tag, Symbolic)

define getTokenCodeNumber(tokenCode)
    match tokenCode
        case Space -> 0
        case VSpace -> 1
        case Newline -> 2
        case Symbolic -> 3
        case Numeric -> 4
        case Character -> 5
        case String -> 6
        case Comment -> 7
        case Invalid -> 8

define isElided(token)
    code := getTokenCodeNumber(getTokenCode(token))
    code = getTokenCodeNumber(Comment) or code = getTokenCodeNumber(VSpace)

define showToken(token)
    token.getTokenTag.getTagLexeme

define eofTag
    Tag("\0", Location("", 0, 0))

define START
    Token(eofTag, Symbolic)

define lex(string)
    pairs(scan(string) ++ [eofTag]).map(uncurry(createToken))

define showToken'(token)
    showTag(getTokenTag(token)) ++ " " ++ (
        match getTokenCode(token)
            case Space -> "Space"
            case VSpace -> "VSpace"
            case Newline -> "Newline"
            case Symbolic -> "Symbolic"
            case Numeric -> "Numeric"
            case Character -> "Character"
            case String -> "String"
            case Comment -> "Comment"
            case Invalid -> "Invalid"
    )

#main(input) := scan(input).map(showTag).joinWith("\n")
#main(input) := lex(input).map(showToken').joinWith("\n")

#*
