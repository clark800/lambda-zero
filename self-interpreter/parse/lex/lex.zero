#* lex.zero

NOFIX := 0
PREFIX := 1
INFIX := 2
POSTFIX := 3
OPENFIX := 4
CLOSEFIX := 5

LocationT ::= {Location(file : List(ℕ), line : ℕ, column : ℕ)}

TagT ::= {Tag(lexeme : List(ℕ), fixity : ℕ, location : LocationT, global : 𝔹)}

getTagLexeme(Tag(lexeme, _, _, _)) := lexeme
getTagFixity(Tag(_, fixity, _, _)) := fixity
getTagLocation(Tag(_, _, location, _)) := location
isGlobal(Tag(_, _, _, global)) := global

renameTag(Tag(_, _, location, global), lexeme, fixity) :=
    Tag(lexeme, fixity, location, global)
veil(tag) := renameTag(tag, "_", NOFIX)
setGlobal(Tag(lexeme, fixity, location, _)) :=
    Tag(lexeme, fixity, location, True)
setTagLocation(location, Tag(lexeme, fixity, _, global)) :=
    Tag(lexeme, fixity, location, global)
addPrefix(Tag(lexeme, fixity, location, global), prefix) :=
    Tag(prefix :: lexeme, fixity, location, global)
isSameLocation(Location(file1, line1, col1), Location(file2, line2, col2)) :=
    file1 =*= file2 and line1 = line2 and col1 = col2
isSameTag(tag1, tag2) :=
    isSameLocation(getTagLocation(tag1), getTagLocation(tag2))

isComment(c) := c = '#'
isLineFeed(c) := c = '\n'
isInvalid(c) := c =/= 0 and isControl(c) and not isLineFeed(c)
isDelimiter(c) := " `.,;@#$()[]{}\"\n\0".any((= c)) or isInvalid(c)
isRepeatable(c) := " `.,;".any((= c))


def startsWithDigit(lexeme)
    if lexeme is n :: _
        isDigit(n)
    False


def isNumeric(lexeme)
    if lexeme is n :: ns
        isDigit(n) or ((n = '+' or n = '-') and startsWithDigit(ns))
    False


def splitQuoteCharacter(quote, ns)
    if ns is n :: ns'
        if n = quote or isLineFeed(n)
            ([], ns)
        n' := if n = '\\' and not isNil(ns') then 2 else 1
        ns.splitAt(n')
    ([], ns)


def shiftSplit((a, b))
    b |> case [] -> (a, b); case n :: ns -> (a ++ [n], ns)


def splitQuote(ns)
    if ns is quote :: ns'
        (a, b) := ns'.splitWith(splitQuoteCharacter(quote))
        if b is quote' :: _
            if quote' = quote
                shiftSplit((quote :: a, b))
            (quote :: a, b)
        (quote :: a, b)
    ([], [])


def splitNumeric(ns)
    (before, after) := ns.splitWhen(isDelimiter)
    if after is n :: ns'
        if n =/= '.' or not startsWithDigit(ns')
            (before, after)
        (before', after') := ns'.splitWhen(isDelimiter)
        (before ++ [n] ++ before', after')
    (before, after)


def splitNewline(ns)
    if ns is n :: ns'
        (before, after) := ns'.splitWhen((=/= ' '))
        (n :: before, after)
    ([], [])


def splitLexeme(ns)
    if ns is c :: ns'
        if c.isLineFeed then splitNewline(ns)
        if c.isQuote then splitQuote(ns)
        if c.isComment then ns.splitWhen(isLineFeed)
        if ns.isNumeric then splitNumeric(ns)
        if c.isRepeatable then ns.splitWhen((=/= c))
        if c.isDelimiter then ([c], ns')
        ns.splitWhen(isDelimiter)
    ([], [])


def advanceLocation(Location(file, line, column), lexeme)
    if lexeme.startsWith("#*")
        (_, after) := lexeme.drop(2).splitWhen((=/= ' '))
        (file', _) := after.splitWhen(isLineFeed)
        Location(file', if isNil(file') then 0 else 1, 0)
    if lexeme.startsWith("\n")
        Location(file, line + 1, length(lexeme))
    Location(file, line, column + length(lexeme))


def splitLexemes(splitter, location, string)
    if string.isNil
        []
    (lexeme, remaining) := splitter(string)
    nextLocation := advanceLocation(location, lexeme)
    Tag(lexeme, NOFIX, location, False) ::
        remaining.splitLexemes(splitter, nextLocation)


def scan(string)
    string.splitLexemes(splitLexeme, Location("", 1, 1))


def showLocation(Location(file, line, column))
    (if isNil(file) then "" else file ++ " ") ++
        "line " ++ showNatural(line) ++ " column " ++ showNatural(column)


def showShortLocation(Location(file, line, column))
    (if isNil(file) then "" else file ++ ":") ++
        showNatural(line) ++ ":" ++ showNatural(column)


def showTag(Tag(lexeme, fixity, _, _))
    if lexeme is c :: _
        if c = 0 then "\\0"
        if c = '\n' then "\\n"
        if fixity = NOFIX then lexeme
        "(" ++ lexeme ++ ")"
    "\\0"


def showQuotedLexeme(lexeme)
    if lexeme is c :: _
        if c = '\n' then "'(end of line)'" else pass
    "'" ++ lexeme ++ "'"


def showTagWithLocation(Tag(lexeme, _, location, _))
    showQuotedLexeme(lexeme) ++ " at " ++ showLocation(location)


def throwError(message, tag)
    abort message ++ " " ++ showTagWithLocation(tag) ++ "\n"


def syntaxError(message, tag)
    throwError("Syntax error: " ++ message, tag)


TokenCode ::= {
    Space, VSpace, Newline, Symbolic, Numeric, Character, String,
    Comment, Invalid
}

TokenT ::= {Token(tag : TagT, code : TokenCode)}

getTokenTag(Token(tag, _)) := tag
getTokenCode(Token(_, code)) := code


def createLineFeedToken(tag, _ @ Tag(nextLexeme, _, _, _))
    if nextLexeme is c :: _
        if isLineFeed(c) or isComment(c)
            Token(tag, VSpace)
        Token(tag, Newline)
    Token(tag, VSpace)


def createToken(tag @ Tag(lexeme, _, _, _), nextTag)
    if lexeme is c :: _
        if c = ' ' then Token(tag, Space)
        if c = '\n' then createLineFeedToken(tag, nextTag)
        if c = '"' then Token(tag, String)
        if c = '\'' then Token(tag, Character)
        if isNumeric(lexeme) then Token(tag, Numeric)
        if isComment(c) then Token(tag, Comment)
        if isInvalid(c) then Token(tag, Invalid)
        Token(tag, Symbolic)
    Token(tag, Symbolic)


def isElided(token)
    match getTokenCode(token)
        case Comment -> True
        case Space -> True
        case VSpace -> True
        case _ -> False


def showToken(token)
    showTag(getTokenTag(token))


def noTag
    Tag("", NOFIX, Location("", 0, 0), False)


def START
    Token(noTag, Symbolic)


def lex(string)
    pairs(scan(string) ++ [noTag]).map(uncurry(createToken))


#main(input) := scan(input).map(showTag).joinWith("\n")

#*
